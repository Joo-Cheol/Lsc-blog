# í–¥ìƒëœ ì‹œìŠ¤í…œ ê°€ì´ë“œ

## ê°œìš”

LSC Blog Automation ì‹œìŠ¤í…œì´ ìš´ì˜Â·í’ˆì§ˆÂ·í˜‘ì—…ì„ ê³ ë ¤í•œ í”„ë¡œë•ì…˜ ë ˆë²¨ë¡œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.

## ì£¼ìš” ê°œì„ ì‚¬í•­

### 1. ì¦ë¶„Â·ì¤‘ë³µ ì œì–´ ì‹œìŠ¤í…œ

#### í¬ë¡¤ëŸ¬ ìŠ¤í† ë¦¬ì§€ (`src/crawler/storage.py`)
- **seen_posts**: ìˆ˜ì§‘ëœ í¬ìŠ¤íŠ¸ ì¶”ì  (URL, logno, content_hash)
- **checkpoints**: ë§ˆì§€ë§‰ ìˆ˜ì§‘ ìœ„ì¹˜ (last_logno)
- **ì¤‘ë³µ ë°©ì§€**: content_hash ê¸°ë°˜ ì¤‘ë³µ ê°ì§€
- **ì¦ë¶„ í¬ë¡¤ë§**: WHERE logno > last_lognoë§Œ ìˆ˜ì§‘

```python
from src.crawler.storage import crawler_storage

# ë§ˆì§€ë§‰ logno ì¡°íšŒ
last_logno = crawler_storage.get_last_logno()

# í¬ìŠ¤íŠ¸ ì¶”ê°€/ì—…ë°ì´íŠ¸
result = crawler_storage.add_seen_post(url, logno, content, title)
# result: "new", "updated", "unchanged"

# ì²´í¬í¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
crawler_storage.update_checkpoint(last_logno, {"total": 100, "new": 20, "updated": 5})
```

### 2. ì„ë² ë”© ìºì‹œ ì‹œìŠ¤í…œ

#### ì„ë² ë”© ìºì‹œ (`src/vector/embedder.py`)
- **chunk_hash**: SHA256 ê¸°ë°˜ ì²­í¬ ì‹ë³„
- **get_or_compute()**: ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ìë™ ì²˜ë¦¬
- **ë°°ì¹˜ ì²˜ë¦¬**: 32ê°œì”© ë°°ì¹˜ ì„ë² ë”©
- **ì ‘ê·¼ í†µê³„**: hit rate, ì ‘ê·¼ ë¹ˆë„ ì¶”ì 

```python
from src.vector.embedder import embedding_cache

# ë‹¨ì¼ ì„ë² ë”©
embedding, chunk_hash = embedding_cache.get_or_compute(chunk_text)

# ë°°ì¹˜ ì„ë² ë”©
embeddings, chunk_hashes = embedding_cache.batch_get_or_compute(chunk_texts)

# ìºì‹œ í†µê³„
stats = embedding_cache.get_cache_stats()
print(f"Hit rate: {stats['total_accesses'] / stats['total_embeddings']:.2%}")
```

### 3. ChromaDB ì¸ë±ìŠ¤ ê´€ë¦¬

#### ì¸ë±ì„œ (`src/vector/chroma_index.py`)
- **chunk_hash ID**: ê³ ì • IDë¡œ ì¤‘ë³µ ë°©ì§€
- **added/skipped ë¡œê·¸**: ì—…ì„œíŠ¸ ê²°ê³¼ ì¶”ì 
- **ë©”íƒ€ë°ì´í„° í•„í„°ë§**: source_url, law_topic, logno ë²”ìœ„
- **ë°°ì¹˜ ì—…ì„œíŠ¸**: 100ê°œì”© ë°°ì¹˜ ì²˜ë¦¬

```python
from src.vector.chroma_index import chroma_indexer

# ì²­í¬ ì—…ì„œíŠ¸
result = chroma_indexer.upsert_chunks(chunks, embeddings, chunk_hashes)
print(f"Added: {result['added']}, Skipped: {result['skipped']}")

# í•„í„° ê²€ìƒ‰
results = chroma_indexer.search(
    query_embedding=embedding,
    top_k=20,
    where_filter={"law_topic": "ì±„ê¶Œì¶”ì‹¬", "logno": {"$gte": 1000}}
)
```

### 4. ë¦¬ë­ì»¤ ì‹œìŠ¤í…œ

#### Cross-Encoder ë¦¬ë­ì»¤ (`src/search/reranker.py`)
- **1ì°¨ ê²€ìƒ‰**: e5 ì„ë² ë”© top-20
- **2ì°¨ ë¦¬ë­í¬**: Cross-Encoder top-6
- **ì ìˆ˜ ê°œì„ **: ì›ë³¸ ì ìˆ˜ vs ë¦¬ë­í¬ ì ìˆ˜ ë¹„êµ
- **ìˆœìœ„ ë³€í™”**: ìƒìŠ¹/í•˜ë½ í†µê³„

```python
from src.search.enhanced_search import enhanced_search

# í†µí•© ê²€ìƒ‰ (1ì°¨ + ë¦¬ë­í¬)
result = enhanced_search.search(
    query="ì±„ê¶Œì¶”ì‹¬ ì ˆì°¨",
    where_filter={"law_topic": "ì±„ê¶Œì¶”ì‹¬"}
)

print(f"Found: {result['stats']['total_found']}")
print(f"Returned: {result['stats']['returned']}")
print(f"Rerank enabled: {result['stats']['rerank_enabled']}")
```

### 5. í’ˆì§ˆ ê°€ë“œ ì‹œìŠ¤í…œ

#### í’ˆì§ˆ ê²€ì‚¬ (`src/generator/quality_guard.py`)
- **ê¸¸ì´ ê²€ì‚¬**: 1,600-1,900ì ë²”ìœ„
- **ì†Œì œëª© ê²€ì‚¬**: ìµœì†Œ 3ê°œ (## ë˜ëŠ” ###)
- **ì²´í¬ë¦¬ìŠ¤íŠ¸**: í•„ìˆ˜ í¬í•¨ ì—¬ë¶€
- **ë””ìŠ¤í´ë ˆì´ë¨¸**: ë²•ì  ê³ ì§€ í¬í•¨ ì—¬ë¶€
- **SEO í‚¤ì›Œë“œ**: ê´€ë ¨ í‚¤ì›Œë“œ 2ê°œ ì´ìƒ
- **ê³µê° ë„ì…ë¶€**: ê³ ê° ê³ ë¯¼ ê³µê° í‘œí˜„

```python
from src.generator.enhanced_generator import enhanced_generator

# í’ˆì§ˆ ê°€ë“œ í†µí•© ìƒì„±
result = enhanced_generator.generate_with_quality_guard(
    query="ì±„ê¶Œì¶”ì‹¬ ì ˆì°¨",
    search_results=search_results
)

print(f"Quality score: {result['quality']['score']:.2%}")
print(f"Passed: {result['quality']['passed']}")
print(f"Attempts: {result['generation']['total_attempts']}")
```

### 6. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

#### í—¬ìŠ¤ ì²´í¬ (`/health`)
- **ì‹œìŠ¤í…œ ìƒíƒœ**: healthy/degraded/unhealthy
- **ê°€ë™ ì‹œê°„**: uptime_seconds
- **ë°ì´í„°ë² ì´ìŠ¤**: SQLite ì—°ê²° ìƒíƒœ
- **ChromaDB**: ì»¬ë ‰ì…˜ ìƒíƒœ, ë¬¸ì„œ ìˆ˜
- **ì„ë² ë”© ìºì‹œ**: ìºì‹œ ìƒíƒœ, ì„ë² ë”© ìˆ˜

#### í†µê³„ API (`/stats`)
- **í¬ë¡¤ëŸ¬ í†µê³„**: ì´ í¬ìŠ¤íŠ¸, ì—…ë°ì´íŠ¸, ë§ˆì§€ë§‰ í¬ë¡¤
- **ChromaDB í†µê³„**: ë¬¸ì„œ ìˆ˜, ì†ŒìŠ¤ë³„/ì£¼ì œë³„ ë¶„í¬
- **ìºì‹œ í†µê³„**: ì„ë² ë”© ìˆ˜, ì ‘ê·¼ í†µê³„, hit rate
- **Provider í†µê³„**: LLM ì œê³µì ìƒíƒœ

## í™˜ê²½ ì„¤ì •

### í™•ì¥ëœ ENV ë³€ìˆ˜

```bash
# ë¦¬ë­ì»¤ ì„¤ì •
RERANK_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
TOPK_FIRST=20
TOPK_FINAL=6
ENABLE_RERANK=true

# ìƒì„± í’ˆì§ˆ ê°€ë“œ
GEN_MIN_CHARS=1600
GEN_MAX_CHARS=1900
GEN_MIN_SUBHEADINGS=3
GEN_REQUIRE_CHECKLIST=true
GEN_REQUIRE_DISCLAIMER=true
GEN_MAX_RETRIES=2

# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
CHROMA_DIR=data/chroma
SEEN_DB=data/crawler_storage.db
EMBEDDING_CACHE_DB=data/embedding_cache.db
```

## ì‚¬ìš© ì˜ˆì‹œ

### 1. í¬ë¡¤ë§ â†’ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸

```python
# 1. ì¦ë¶„ í¬ë¡¤ë§
from src.crawler.storage import crawler_storage
last_logno = crawler_storage.get_last_logno()

# í¬ë¡¤ë§ ì‹¤í–‰ (logno > last_lognoë§Œ)
new_posts = crawl_naver_blog(since_logno=last_logno)

# 2. ì¤‘ë³µ ì œì–´ ë° ì €ì¥
for post in new_posts:
    result = crawler_storage.add_seen_post(
        post['url'], post['logno'], post['content'], post['title']
    )
    if result in ['new', 'updated']:
        # ì¸ë±ì‹± ëŒ€ìƒì— ì¶”ê°€
        process_for_indexing(post)

# 3. ì²´í¬í¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
max_logno = max(post['logno'] for post in new_posts)
crawler_storage.update_checkpoint(max_logno, stats)
```

### 2. ê²€ìƒ‰ â†’ ìƒì„± íŒŒì´í”„ë¼ì¸

```python
# 1. í–¥ìƒëœ ê²€ìƒ‰
from src.search.enhanced_search import enhanced_search
search_result = enhanced_search.search_with_filters(
    query="ì±„ê¶Œì¶”ì‹¬ ì ˆì°¨",
    law_topic="ì±„ê¶Œì¶”ì‹¬"
)

# 2. í’ˆì§ˆ ê°€ë“œ í†µí•© ìƒì„±
from src.generator.enhanced_generator import enhanced_generator
generation_result = enhanced_generator.generate_with_quality_guard(
    query="ì±„ê¶Œì¶”ì‹¬ ì ˆì°¨",
    search_results=search_result['documents']
)

# 3. ê²°ê³¼ í™•ì¸
if generation_result['quality']['passed']:
    print("âœ… ê³ í’ˆì§ˆ ì½˜í…ì¸  ìƒì„± ì™„ë£Œ")
    content = generation_result['content']
else:
    print("âš ï¸ í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬, ì¬ì‹œë„ í•„ìš”")
    print(f"ì‹¤íŒ¨ í•­ëª©: {generation_result['quality']['failed_checks']}")
```

### 3. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

```bash
# í—¬ìŠ¤ ì²´í¬
curl http://localhost:8000/health

# í†µê³„ ì¡°íšŒ
curl http://localhost:8000/stats

# ì„¤ì • í™•ì¸
curl http://localhost:8000/config
```

## ì„±ëŠ¥ ì§€í‘œ

### ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

1. **í¬ë¡¤ë§ íš¨ìœ¨ì„±**
   - ì¦ë¶„ í¬ë¡¤ë§: 90% ì‹œê°„ ë‹¨ì¶•
   - ì¤‘ë³µ ì œê±°: 100% ì •í™•ë„

2. **ì„ë² ë”© ì„±ëŠ¥**
   - ìºì‹œ íˆíŠ¸ìœ¨: 70-80%
   - ë°°ì¹˜ ì²˜ë¦¬: 3-5ë°° ì†ë„ í–¥ìƒ

3. **ê²€ìƒ‰ ì •í™•ë„**
   - ë¦¬ë­í‚¹: 15-25% ì •í™•ë„ í–¥ìƒ
   - í•„í„°ë§: 50% ë…¸ì´ì¦ˆ ê°ì†Œ

4. **ìƒì„± í’ˆì§ˆ**
   - í’ˆì§ˆ ê°€ë“œ: 80% ì´ìƒ í†µê³¼ìœ¨
   - ìë™ ì¬ì‹œë„: 95% ìµœì¢… ì„±ê³µë¥ 

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

1. **ChromaDB ì—°ê²° ì‹¤íŒ¨**
   ```bash
   # ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
   ls -la data/chroma/
   
   # ê¶Œí•œ í™•ì¸
   chmod 755 data/
   ```

2. **ì„ë² ë”© ìºì‹œ ì˜¤ë¥˜**
   ```bash
   # ìºì‹œ íŒŒì¼ í™•ì¸
   ls -la data/embedding_cache.db
   
   # ìºì‹œ ì´ˆê¸°í™” (í•„ìš”ì‹œ)
   rm data/embedding_cache.db
   ```

3. **í’ˆì§ˆ ê°€ë“œ ì‹¤íŒ¨**
   ```python
   # í’ˆì§ˆ ê¸°ì¤€ ì™„í™”
   quality_guard = QualityGuard(
       min_chars=1200,  # 1600 â†’ 1200
       min_subheadings=2  # 3 â†’ 2
   )
   ```

## ë‹¤ìŒ ë‹¨ê³„

1. **ë©”íŠ¸ë¦­ ìˆ˜ì§‘**: Prometheus/Grafana ì—°ë™
2. **ì•Œë¦¼ ì‹œìŠ¤í…œ**: Slack/ì´ë©”ì¼ ì•Œë¦¼
3. **A/B í…ŒìŠ¤íŠ¸**: ë¦¬ë­ì»¤ ì„±ëŠ¥ ë¹„êµ
4. **ìë™í™”**: ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸
5. **í™•ì¥ì„±**: Kubernetes ë°°í¬

ì´ì œ ì‹œìŠ¤í…œì´ í”„ë¡œë•ì…˜ ë ˆë²¨ì˜ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì„ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤! ğŸš€
