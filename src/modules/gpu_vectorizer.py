#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPU ê°€ì† ë²¡í„°í™” ì‹œìŠ¤í…œ
sentence-transformersë¥¼ ì‚¬ìš©í•œ ê³ ì† ì„ë² ë”© ìƒì„±
"""

import os
import json
import argparse
from typing import List, Dict, Any
import torch

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("âš ï¸ sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

try:
    import chromadb
    from chromadb.config import Settings
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False
    print("âš ï¸ ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

class GPUEmbeddingFunction:
    """GPU ê°€ì† ì„ë² ë”© í•¨ìˆ˜"""
    
    def __init__(self, model_name: str = "jhgan/ko-sroberta-multitask"):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ëª…
        """
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            raise ImportError("sentence-transformersê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        print(f"ğŸš€ GPU ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {model_name}")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ê°•ì œ ì‚¬ìš©
        if torch.cuda.is_available():
            self.device = "cuda"
            print(f"ğŸš€ GPU ì‚¬ìš© ê°€ëŠ¥! CUDA ë””ë°”ì´ìŠ¤ë¡œ ì„¤ì •")
        else:
            self.device = "cpu"
            print(f"âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            print(f"ğŸ’¡ GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ CUDAê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        print(f"ğŸ’» ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = SentenceTransformer(model_name, device=self.device)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def __call__(self, input: List[str]) -> List[List[float]]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (ChromaDB 0.4.16+ í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤)
        
        Args:
            input: ë³€í™˜í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        if not input:
            return []
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„ë² ë”© ìƒì„± (GPU ì‚¬ìš© ì‹œ ë” í° ë°°ì¹˜ í¬ê¸°)
        batch_size = 64 if self.device == "cuda" else 16
        print(f"ğŸ”„ ë°°ì¹˜ í¬ê¸°: {batch_size} (ë””ë°”ì´ìŠ¤: {self.device})")
        
        embeddings = self.model.encode(
            input,
            batch_size=batch_size,
            show_progress_bar=True,
            convert_to_tensor=False
        )
        
        return embeddings.tolist()
    
    def encode(self, input_texts: List[str]) -> List[List[float]]:
        """
        ChromaDB í˜¸í™˜ì„ ìœ„í•œ encode ë©”ì„œë“œ
        """
        return self.__call__(input_texts)

class GPUVectorizer:
    """GPU ê°€ì† ë²¡í„°í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 chroma_path: str = "src/data/indexes/chroma",
                 collection_name: str = "naver_blog_all",
                 model_name: str = "jhgan/ko-sroberta-multitask"):
        """
        ì´ˆê¸°í™”
        
        Args:
            chroma_path: ChromaDB ì €ì¥ ê²½ë¡œ
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            model_name: ì„ë² ë”© ëª¨ë¸ëª…
        """
        self.chroma_path = chroma_path
        self.collection_name = collection_name
        
        # GPU ì„ë² ë”© í•¨ìˆ˜ ì´ˆê¸°í™”
        self.embedding_function = GPUEmbeddingFunction(model_name)
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if CHROMADB_AVAILABLE:
            self.client = chromadb.PersistentClient(
                path=chroma_path,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            self._init_collection()
    
    def _init_collection(self):
        """ChromaDB ì»¬ë ‰ì…˜ ì´ˆê¸°í™”"""
        try:
            self.collection = self.client.get_collection(self.collection_name)
            print(f"ğŸ“š ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ: {self.collection_name}")
        except Exception:
            try:
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    embedding_function=self.embedding_function,
                    metadata={"description": "ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ ì €ì¥ì†Œ (GPU ê°€ì†)"}
                )
                print(f"ğŸ“š ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name} (GPU ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš©)")
            except Exception as e:
                print(f"âš ï¸ GPU ì„ë² ë”© í•¨ìˆ˜ë¡œ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ ì„ë² ë”© í•¨ìˆ˜ë¡œ ì‹œë„
                try:
                    import chromadb.utils.embedding_functions as embedding_functions
                    default_embedding_function = embedding_functions.DefaultEmbeddingFunction()
                    self.collection = self.client.create_collection(
                        name=self.collection_name,
                        embedding_function=default_embedding_function,
                        metadata={"description": "ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ ì €ì¥ì†Œ (ê¸°ë³¸ ì„ë² ë”©)"}
                    )
                    print(f"ğŸ“š ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name} (ê¸°ë³¸ ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš©)")
                except Exception as e2:
                    # ì„ë² ë”© í•¨ìˆ˜ ì—†ì´ ìƒì„±
                    self.collection = self.client.create_collection(
                        name=self.collection_name,
                        metadata={"description": "ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ ì €ì¥ì†Œ (ì„ë² ë”© í•¨ìˆ˜ ì—†ìŒ)"}
                    )
                    print(f"ğŸ“š ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name} (ì„ë² ë”© í•¨ìˆ˜ ì—†ìŒ)")
    
    def chunk_text(self, text: str, max_tokens: int = 1200, overlap: int = 200) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        if not text:
            return [""]
        
        # ê°„ë‹¨í•œ ê¸€ììˆ˜ ê¸°ë°˜ ì²­í‚¹
        max_chars = max_tokens * 2  # ëŒ€ëµì ì¸ ë³€í™˜
        step = max_chars - overlap
        
        chunks = []
        for i in range(0, len(text), step):
            chunk = text[i:i + max_chars]
            if chunk.strip():
                chunks.append(chunk.strip())
        
        return chunks if chunks else [""]
    
    def vectorize_documents(self, docs: List[Dict], run_id: str, source_file: str) -> int:
        """
        ë¬¸ì„œë“¤ì„ ë²¡í„°í™”í•˜ì—¬ ChromaDBì— ì €ì¥
        
        Args:
            docs: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            run_id: ì‹¤í–‰ ID
            source_file: ì†ŒìŠ¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì €ì¥ëœ ì²­í¬ ìˆ˜
        """
        if not CHROMADB_AVAILABLE:
            print("âŒ ChromaDBê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return 0
        
        print(f"ğŸ“„ {len(docs)}ê°œ ë¬¸ì„œ ë²¡í„°í™” ì‹œì‘...")
        
        ids, texts, metas = [], [], []
        
        for doc in docs:
            chunks = self.chunk_text(doc.get("content", ""), max_tokens=1200, overlap=200)
            
            for i, chunk in enumerate(chunks):
                # logNo ë˜ëŠ” logno í•„ë“œ ì‚¬ìš© (ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼)
                logno = doc.get("logNo") or doc.get("logno", "unknown")
                chunk_id = f'{logno}:{i:03d}'
                ids.append(chunk_id)
                texts.append(chunk)
                metas.append({
                    "logno": int(logno) if str(logno).isdigit() else 0,
                    "chunk_idx": i,
                    "category_no": int(doc.get("category_no", 0)),
                    "posted_at": doc.get("posted_at", ""),
                    "title": doc.get("title", ""),
                    "url": doc.get("url", ""),
                    "run_id": run_id,
                    "source_file": source_file,
                    "content_hash": doc.get("content_hash", "")
                })
        
        print(f"ğŸ”§ {len(ids)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
        
        # ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ upsert
        batch_size = 100
        total_upserted = 0
        
        for i in range(0, len(ids), batch_size):
            batch_ids = ids[i:i + batch_size]
            batch_texts = texts[i:i + batch_size]
            batch_metas = metas[i:i + batch_size]
            
            try:
                self.collection.upsert(
                    ids=batch_ids,
                    documents=batch_texts,
                    metadatas=batch_metas
                )
                total_upserted += len(batch_ids)
                print(f"ğŸ“¤ ë°°ì¹˜ {i//batch_size + 1}: {len(batch_ids)}ê°œ ì²­í¬ upsert ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ {i//batch_size + 1} upsert ì‹¤íŒ¨: {str(e)}")
                # ê°œë³„ ì²­í¬ë¡œ ì‹œë„
                for j, (chunk_id, chunk_text, chunk_meta) in enumerate(zip(batch_ids, batch_texts, batch_metas)):
                    try:
                        self.collection.upsert(
                            ids=[chunk_id],
                            documents=[chunk_text],
                            metadatas=[chunk_meta]
                        )
                        total_upserted += 1
                    except Exception as e2:
                        print(f"âŒ ê°œë³„ ì²­í¬ {chunk_id} upsert ì‹¤íŒ¨: {str(e2)}")
        
        return total_upserted
    
    def get_stats(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ í†µê³„ ë°˜í™˜"""
        if not CHROMADB_AVAILABLE:
            return {"error": "ChromaDB ì‚¬ìš© ë¶ˆê°€"}
        
        try:
            count = self.collection.count()
            return {
                "collection_name": self.collection_name,
                "total_chunks": count,
                "device": self.embedding_function.device,
                "model_name": self.embedding_function.model.get_sentence_embedding_dimension()
            }
        except Exception as e:
            return {"error": str(e)}

def main():
    parser = argparse.ArgumentParser(description="GPU ê°€ì† ë²¡í„°í™” ì‹œìŠ¤í…œ")
    parser.add_argument("--input", required=True, help="ì…ë ¥ JSONL íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--run-id", required=True, help="ì‹¤í–‰ ID")
    parser.add_argument("--source-file", required=True, help="ì†ŒìŠ¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--chroma-path", default="src/data/indexes/chroma",
                       help="ChromaDB ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--collection", default="naver_blog_all",
                       help="ì»¬ë ‰ì…˜ ì´ë¦„")
    parser.add_argument("--model", default="jhgan/ko-sroberta-multitask",
                       help="ì„ë² ë”© ëª¨ë¸ëª…")
    parser.add_argument("--stats", action="store_true", help="í†µê³„ ì¶œë ¥")
    
    args = parser.parse_args()
    
    try:
        # GPU ë²¡í„°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        vectorizer = GPUVectorizer(
            chroma_path=args.chroma_path,
            collection_name=args.collection,
            model_name=args.model
        )
        
        # í†µê³„ ì¶œë ¥
        if args.stats:
            stats = vectorizer.get_stats()
            print("ğŸ“Š ë²¡í„°í™” ì‹œìŠ¤í…œ í†µê³„:")
            if "error" in stats:
                print(f"  - ì˜¤ë¥˜: {stats['error']}")
            else:
                print(f"  - ì»¬ë ‰ì…˜: {stats['collection_name']}")
                print(f"  - ì´ ì²­í¬ ìˆ˜: {stats['total_chunks']}ê°œ")
                print(f"  - ë””ë°”ì´ìŠ¤: {stats['device']}")
                print(f"  - ëª¨ë¸ ì°¨ì›: {stats['model_name']}")
            return
        
        # JSONL íŒŒì¼ ë¡œë“œ
        print(f"ğŸ“„ JSONL íŒŒì¼ ë¡œë“œ: {args.input}")
        docs = []
        with open(args.input, "r", encoding="utf-8") as f:
            for line in f:
                docs.append(json.loads(line.strip()))
        
        print(f"ğŸ“š {len(docs)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
        
        # ë²¡í„°í™” ì‹¤í–‰
        upserted_count = vectorizer.vectorize_documents(
            docs, args.run_id, args.source_file
        )
        
        print(f"âœ… ë²¡í„°í™” ì™„ë£Œ!")
        print(f"  - ì²˜ë¦¬ëœ ë¬¸ì„œ: {len(docs)}ê°œ")
        print(f"  - ì €ì¥ëœ ì²­í¬: {upserted_count}ê°œ")
        
        # ìµœì¢… í†µê³„
        final_stats = vectorizer.get_stats()
        if "error" not in final_stats:
            print(f"  - ì´ ë²¡í„° ìˆ˜: {final_stats['total_chunks']}ê°œ")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
