#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹ ê·œ í¬ìŠ¤íŠ¸ë¥¼ ì²­í¬â†’ì„ë² ë”©â†’ChromaDB upsert
"""

import json
import os
import argparse
from pathlib import Path
from typing import List, Dict, Any
from utils_text import split_chunks, normalize_category_name

try:
    import chromadb
    from chromadb.config import Settings
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False
    print("âš ï¸ ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install chromadb")

def load_new_docs(jsonl_path: str) -> List[Dict[str, Any]]:
    """JSONL íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
    if not os.path.exists(jsonl_path):
        raise FileNotFoundError(f"JSONL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jsonl_path}")
    
    docs = []
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            try:
                doc = json.loads(line.strip())
                docs.append(doc)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ ë¼ì¸ {line_num} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
    
    print(f"ğŸ“„ {len(docs)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    return docs

def prepare_chunks_for_chroma(docs: List[Dict[str, Any]], run_id: str, source_file: str) -> tuple:
    """
    ë¬¸ì„œë“¤ì„ ChromaDBìš© ì²­í¬ë¡œ ë³€í™˜
    
    Returns:
        (ids, documents, metadatas) íŠœí”Œ
    """
    ids = []
    documents = []
    metadatas = []
    
    for doc in docs:
        logno = int(doc.get("logno", doc.get("post_no", 0)))
        content = doc.get("content", "")
        category_no = int(doc.get("category_no", 0))
        
        # í…ìŠ¤íŠ¸ ì²­í‚¹ (ê°€ì´ë“œ: 300-600 í† í°, 10-20% ì˜¤ë²„ë©)
        chunks = split_chunks(content, max_tokens=500, overlap=100)
        
        for chunk_idx, chunk_text in enumerate(chunks):
            # ê³ ìœ  ID ìƒì„±: logno:chunk_idx
            chunk_id = f"{logno}:{chunk_idx:03d}"
            
            # ë©”íƒ€ë°ì´í„° êµ¬ì„± (ê°€ì´ë“œ ìŠ¤í‚¤ë§ˆ)
            metadata = {
                "cat": normalize_category_name(category_no),
                "date": doc.get("published_at", doc.get("posted_at", "")),
                "title": doc.get("title", ""),
                "url": doc.get("url", ""),
                "author": doc.get("author", ""),
                "post_type": "blog_post",
                "logno": logno,
                "chunk_idx": chunk_idx,
                "run_id": run_id,
                "source_file": source_file,
                "category_no": category_no,
                "category_name": normalize_category_name(category_no),
                "content_hash": doc.get("content_hash", ""),
                "chunk_count": len(chunks)
            }
            
            ids.append(chunk_id)
            documents.append(chunk_text)
            metadatas.append(metadata)
    
    print(f"ğŸ”§ {len(ids)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
    return ids, documents, metadatas

def upsert_to_chroma(ids: List[str], documents: List[str], metadatas: List[Dict], 
                    chroma_path: str, collection_name: str) -> int:
    """ChromaDBì— ì²­í¬ë“¤ upsert"""
    if not CHROMADB_AVAILABLE:
        raise ImportError("ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = chromadb.PersistentClient(
        path=chroma_path,
        settings=Settings(
            anonymized_telemetry=False,
            allow_reset=True
        )
    )
    
    # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
    try:
        collection = client.get_collection(collection_name)
        print(f"ğŸ“š ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ: {collection_name}")
    except Exception as e:
        # E5-base ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš© (cosine ê±°ë¦¬ + ì •ê·œí™”)
        try:
            import chromadb.utils.embedding_functions as embedding_functions
            embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name="intfloat/multilingual-e5-base",
                normalize_embeddings=True
            )
            collection = client.create_collection(
                name=collection_name,
                embedding_function=embedding_function,
                metadata={
                    "description": "ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì±„ê¶Œì¶”ì‹¬ í¬ìŠ¤íŠ¸ ë²¡í„° ì €ì¥ì†Œ",
                    "embedding_model": "intfloat/multilingual-e5-base",
                    "distance_metric": "cosine",
                    "normalize_embeddings": True
                }
            )
            print(f"ğŸ“š ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {collection_name} (E5-base ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš©)")
        except Exception as e2:
            # ê¸°ë³¸ ì„ë² ë”© í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ ì„ë² ë”© í•¨ìˆ˜ ì—†ì´ ìƒì„±
            collection = client.create_collection(
                name=collection_name,
                metadata={"description": "ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì±„ê¶Œì¶”ì‹¬ í¬ìŠ¤íŠ¸ ë²¡í„° ì €ì¥ì†Œ"}
            )
            print(f"ğŸ“š ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {collection_name} (ì„ë² ë”© í•¨ìˆ˜ ì—†ìŒ)")
    
    # ë°°ì¹˜ í¬ê¸° ì„¤ì • (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
    batch_size = 100
    total_upserted = 0
    
    for i in range(0, len(ids), batch_size):
        batch_ids = ids[i:i + batch_size]
        batch_docs = documents[i:i + batch_size]
        batch_metas = metadatas[i:i + batch_size]
        
        try:
            # Upsert ì‹¤í–‰
            collection.upsert(
                ids=batch_ids,
                documents=batch_docs,
                metadatas=batch_metas
            )
            total_upserted += len(batch_ids)
            print(f"ğŸ“¤ ë°°ì¹˜ {i//batch_size + 1}: {len(batch_ids)}ê°œ ì²­í¬ upsert ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ {i//batch_size + 1} upsert ì‹¤íŒ¨: {e}")
            # ê°œë³„ upsert ì‹œë„
            for j, (chunk_id, doc, meta) in enumerate(zip(batch_ids, batch_docs, batch_metas)):
                try:
                    collection.upsert(
                        ids=[chunk_id],
                        documents=[doc],
                        metadatas=[meta]
                    )
                    total_upserted += 1
                except Exception as e2:
                    print(f"âŒ ê°œë³„ ì²­í¬ {chunk_id} upsert ì‹¤íŒ¨: {e2}")
    
    print(f"âœ… ì´ {total_upserted}ê°œ ì²­í¬ upsert ì™„ë£Œ")
    return total_upserted

def verify_chroma_data(collection_name: str, chroma_path: str, run_id: str = None, 
                      source_file: str = None) -> Dict[str, int]:
    """ChromaDB ë°ì´í„° ê²€ì¦"""
    if not CHROMADB_AVAILABLE:
        return {}
    
    client = chromadb.PersistentClient(path=chroma_path)
    collection = client.get_collection(collection_name)
    
    verification = {}
    
    # ì „ì²´ ë²¡í„° ìˆ˜
    total_count = collection.count()
    verification["total_vectors"] = total_count
    
    # run_idë³„ ë²¡í„° ìˆ˜
    if run_id:
        run_results = collection.get(where={"run_id": run_id}, limit=1000000)
        verification[f"run_{run_id}_vectors"] = len(run_results["ids"])
    
    # source_fileë³„ ë²¡í„° ìˆ˜
    if source_file:
        file_results = collection.get(where={"source_file": source_file}, limit=1000000)
        verification[f"file_vectors"] = len(file_results["ids"])
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë²¡í„° ìˆ˜
    category_results = collection.get(where={"category_no": 6}, limit=1000000)  # ì±„ê¶Œì¶”ì‹¬
    verification["category_6_vectors"] = len(category_results["ids"])
    
    return verification

def main():
    parser = argparse.ArgumentParser(description="ì‹ ê·œ í¬ìŠ¤íŠ¸ë¥¼ ChromaDBì— ë²¡í„°í™”")
    parser.add_argument("--input", required=True, help="ì‹ ê·œ í¬ìŠ¤íŠ¸ JSONL íŒŒì¼")
    parser.add_argument("--run-id", required=True, help="ì‹¤í–‰ ID")
    parser.add_argument("--source-file", required=True, help="ì›ë³¸ ìŠ¤ëƒ…ìƒ· íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--chroma-path", default="src/data/indexes/chroma", help="ChromaDB ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--collection", default="naver_blog_debt_collection", help="ì»¬ë ‰ì…˜ ì´ë¦„")
    parser.add_argument("--verify", action="store_true", help="ë²¡í„°í™” í›„ ê²€ì¦ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    if not CHROMADB_AVAILABLE:
        print("âŒ ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜ ëª…ë ¹: pip install chromadb")
        return
    
    try:
        # 1. ë¬¸ì„œ ë¡œë“œ
        docs = load_new_docs(args.input)
        if not docs:
            print("ğŸ“ ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ì²­í¬ ì¤€ë¹„
        ids, documents, metadatas = prepare_chunks_for_chroma(
            docs, args.run_id, args.source_file
        )
        
        # 3. ChromaDB upsert
        upserted_count = upsert_to_chroma(
            ids, documents, metadatas, 
            args.chroma_path, args.collection
        )
        
        # 4. ê²€ì¦
        if args.verify:
            verification = verify_chroma_data(
                args.collection, args.chroma_path, 
                args.run_id, args.source_file
            )
            print(f"\nğŸ” ê²€ì¦ ê²°ê³¼:")
            for key, value in verification.items():
                print(f"  - {key}: {value}")
        
        print(f"\nğŸ‰ ë²¡í„°í™” ì™„ë£Œ!")
        print(f"  - ì²˜ë¦¬ëœ ë¬¸ì„œ: {len(docs)}ê°œ")
        print(f"  - ìƒì„±ëœ ì²­í¬: {len(ids)}ê°œ")
        print(f"  - Upsertëœ ë²¡í„°: {upserted_count}ê°œ")
        
    except Exception as e:
        print(f"âŒ ë²¡í„°í™” ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()
