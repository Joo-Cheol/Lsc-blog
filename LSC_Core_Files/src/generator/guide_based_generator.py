"""
ê°€ì´ë“œ ê¸°ë°˜ 2ë‹¨ê³„ ìƒì„± íŒŒì´í”„ë¼ì¸
- Draft (ì‚¬ì‹¤ ì´ˆì•ˆ) â†’ Rewrite (ìŠ¤íƒ€ì¼ ì ìš©)
- í’ˆì§ˆ ê²Œì´íŠ¸ í†µí•©
- ê°€ì´ë“œ í”„ë¡¬í”„íŠ¸ ì½”ì–´ ì ìš©
"""
import time
import json
import re
import hashlib
from typing import Dict, Any, List, Optional
from collections import Counter
import numpy as np

class GuideBasedGenerator:
    """ê°€ì´ë“œ ê¸°ë°˜ 2ë‹¨ê³„ ìƒì„± íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.config = {
            # ê¸¸ì´ ì„¤ì •
            "draft_min_length": 900,
            "draft_max_length": 1100,
            "rewrite_min_length": 1600,
            "rewrite_max_length": 1900,
            
            # í’ˆì§ˆ ê²Œì´íŠ¸ ì„ê³„ê°’
            "ngram8_threshold": 0.18,
            "min_subheadings": 3,
            "min_checklists": 1,
            "max_sentences_per_paragraph": 4,
            "forbidden_words": ["ë˜í•œ", "ë”ë¶ˆì–´", "ë¬´ë£Œìƒë‹´", "ì¦‰ì‹œì—°ë½", "100%"],
            
            # ì‚¬ë¡€ ë‹¤ì–‘ì„± ë²”ìœ„
            "amount_range": (1500000, 6200000),  # 150ë§Œì› ~ 620ë§Œì›
            "period_range": (2, 8),  # 2ì£¼ ~ 8ì£¼
            "regions": ["ì„œìš¸", "ê²½ê¸°", "ì¸ì²œ", "ë¶€ì‚°", "ëŒ€êµ¬", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°"],
            "debtor_types": ["ê°œì¸", "ë²•ì¸", "í”„ë¦¬ëœì„œ", "ì†Œìƒê³µì¸"],
            "reactions": ["ë¶„í• ìƒí™˜", "ì—°ë½íšŒí”¼", "ì£¼ì†Œë¶ˆëª…", "í˜‘ì¡°ì ", "ê±°ë¶€ì "]
        }
    
    def generate_post(self, topic: str, search_results: List[Dict], 
                     category: str = "ì±„ê¶Œì¶”ì‹¬") -> Dict[str, Any]:
        """
        2ë‹¨ê³„ ìƒì„± íŒŒì´í”„ë¼ì¸
        
        Args:
            topic: ì£¼ì œ
            search_results: ê²€ìƒ‰ ê²°ê³¼
            category: ì¹´í…Œê³ ë¦¬
            
        Returns:
            ìƒì„± ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            # 1) ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ ë° MMR ì¤‘ë³µ ì œê±°
            filtered_results = self._filter_and_deduplicate(search_results, top_k=8)
            
            # 2) ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ (ë¶ˆë¦¿ í¬ì¸íŠ¸)
            fact_snippets = self._extract_fact_snippets(filtered_results)
            style_snippets = self._extract_style_snippets(filtered_results)
            
            # 3) 1ë‹¨ê³„: Draft ìƒì„± (ì‚¬ì‹¤ ì´ˆì•ˆ)
            print("ğŸ“ 1ë‹¨ê³„: Draft ìƒì„± ì¤‘...")
            draft = self._generate_draft(topic, fact_snippets)
            
            # 4) 2ë‹¨ê³„: Rewrite ìƒì„± (ìŠ¤íƒ€ì¼ ì ìš©)
            print("âœ¨ 2ë‹¨ê³„: Rewrite ìƒì„± ì¤‘...")
            body_markdown = self._generate_rewrite(draft, topic, style_snippets, fact_snippets)
            
            # 5) í’ˆì§ˆ ê²Œì´íŠ¸ ê²€ì¦
            print("ğŸ” í’ˆì§ˆ ê²€ì¦ ì¤‘...")
            validation_result = self._validate_content(body_markdown, filtered_results)
            
            # 6) í‘œì ˆ ê²€ì¦
            plagiarism_result = self._check_plagiarism(body_markdown, filtered_results)
            
            # 7) ì‹¤íŒ¨ ì‹œ ìë™ ìˆ˜ì •
            if not validation_result["ok"] or not plagiarism_result["ok"]:
                print("âš ï¸ í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ - ìë™ ìˆ˜ì • ì‹œë„...")
                body_markdown = self._auto_fix(body_markdown, validation_result, plagiarism_result)
                
                # ì¬ê²€ì¦
                validation_result = self._validate_content(body_markdown, filtered_results)
                plagiarism_result = self._check_plagiarism(body_markdown, filtered_results)
            
            # 8) ì œëª© ì¶”ì¶œ
            title = self._extract_title(body_markdown)
            
            # 9) í†µê³„ ê³„ì‚°
            latency_ms = int((time.time() - start_time) * 1000)
            
            return {
                "success": True,
                "title": title,
                "body_markdown": body_markdown,
                "sources": self._format_sources(filtered_results),
                "stats": {
                    "latency_ms": latency_ms,
                    "lint_ok": validation_result["ok"],
                    "style_score": validation_result.get("style_score", 0.0),
                    "plag": {
                        "ok": plagiarism_result["ok"],
                        "ngram8": plagiarism_result.get("ngram8_overlap", 0.0),
                        "cosine_max": plagiarism_result.get("cosine_max", 0.0),
                        "simhash_dist": plagiarism_result.get("simhash_dist", 0)
                    }
                }
            }
            
        except Exception as e:
            print(f"âŒ ìƒì„± íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "title": f"{topic} ê´€ë ¨ ë²•ì  ê²€í† ",
                "body_markdown": self._fallback_content(topic),
                "sources": [],
                "stats": {
                    "latency_ms": int((time.time() - start_time) * 1000),
                    "lint_ok": False,
                    "style_score": 0.0,
                    "plag": {"ok": False, "ngram8": 0.0, "cosine_max": 0.0, "simhash_dist": 0}
                }
            }
    
    def _filter_and_deduplicate(self, results: List[Dict], top_k: int) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ ë° MMR ì¤‘ë³µ ì œê±°"""
        # ì ìˆ˜ í•„í„°ë§ (0.78 ì´ìƒ)
        filtered = [r for r in results if r.get("similarity", 0) >= 0.78]
        
        # MMR ì¤‘ë³µ ì œê±° (ê°„ë‹¨í•œ êµ¬í˜„)
        deduplicated = []
        seen_titles = set()
        
        for result in filtered:
            title = result.get("title", "")
            if title not in seen_titles and len(deduplicated) < top_k:
                deduplicated.append(result)
                seen_titles.add(title)
        
        return deduplicated
    
    def _extract_fact_snippets(self, results: List[Dict]) -> str:
        """ì‚¬ì‹¤ ìŠ¤ë‹ˆí« ì¶”ì¶œ (ì ˆì°¨Â·ì„œë¥˜Â·ê¸°ê°„Â·ì£¼ì˜ ìš”ì§€)"""
        facts = []
        for result in results[:5]:  # ìƒìœ„ 5ê°œë§Œ
            content = result.get("content", "")
            # í•µì‹¬ ì‚¬ì‹¤ë§Œ ì¶”ì¶œ (ê°„ë‹¨í•œ êµ¬í˜„)
            sentences = content.split(".")
            for sentence in sentences[:3]:  # ê° ë¬¸ì„œì—ì„œ 3ë¬¸ì¥ë§Œ
                if len(sentence.strip()) > 20:
                    facts.append(f"â€¢ {sentence.strip()}")
        
        return "\n".join(facts[:15])  # ìµœëŒ€ 15ê°œ
    
    def _extract_style_snippets(self, results: List[Dict]) -> str:
        """ìŠ¤íƒ€ì¼ ìŠ¤ë‹ˆí« ì¶”ì¶œ (í†¤ íŒíŠ¸ 1-3ë¬¸ì¥)"""
        styles = []
        for result in results[:3]:  # ìƒìœ„ 3ê°œë§Œ
            content = result.get("content", "")
            # ë„¤ì´ë²„ ë¸”ë¡œê·¸ í†¤ì˜ ë¬¸ì¥ ì¶”ì¶œ
            sentences = content.split(".")
            for sentence in sentences:
                if any(word in sentence for word in ["í•©ë‹ˆë‹¤", "ë©ë‹ˆë‹¤", "ì…ë‹ˆë‹¤"]) and len(sentence.strip()) > 15:
                    styles.append(sentence.strip())
                    break
        
        return "\n".join(styles[:3])  # ìµœëŒ€ 3ê°œ
    
    def _generate_draft(self, topic: str, fact_snippets: str) -> str:
        """1ë‹¨ê³„: ì‚¬ì‹¤ ì´ˆì•ˆ ìƒì„± (900-1100ì)"""
        # ê°€ì´ë“œ í”„ë¡¬í”„íŠ¸ ì½”ì–´ ì ìš©
        prompt = f"""
[ì—­í• ] ë²•ë¬´ë²•ì¸ ë¸”ë¡œê·¸ ì—ë””í„°(í•œêµ­ì–´). ì±„ê¶Œì ê´€ì .

[ì‚¬ì‹¤ ì‚¬ìš© ê·œì¹™]
ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ì˜ ì‚¬ì‹¤(ì •ì˜/ì ˆì°¨/ì„œë¥˜/ê¸°ê°„/ì£¼ì˜)ë§Œ ê·¼ê±°ë¡œ í•˜ë˜, ë¬¸ì¥Â·í‘œí˜„ì€ ì „ë¶€ ìƒˆë¡œ ì‘ì„±.
ì‚¬ë¡€ì˜ ê¸ˆì•¡/ë‚ ì§œ/ì§€ì—­/ë¶„í• íšŸìˆ˜ëŠ” í˜„ì‹¤ ë²”ìœ„ì—ì„œ ìƒˆë¡œ êµ¬ì„±.

[êµ¬ì¡°/ê¸¸ì´]
ë„ì… â†’ ë¬¸ì œ ì¸ì‹ â†’ ë²•ì  ê·¼ê±°/ì ˆì°¨ â†’ ì‹¤ë¬´ ì¡°ì–¸ â†’ ê²°ë¡ .
ë³¸ë¬¸ 900-1100ì, ë¶ˆë¦¿/ìˆ«ì ì¤‘ì‹¬.

[FACT_SNIPPETS] (ì ˆì°¨Â·ì„œë¥˜Â·ê¸°ê°„Â·ì£¼ì˜ ìš”ì§€)
{fact_snippets}

[ì¶œë ¥] ì‚¬ì‹¤ ì´ˆì•ˆë§Œ ì¶œë ¥.
"""
        
        # ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„± (ì‹¤ì œë¡œëŠ” LLM í˜¸ì¶œ)
        draft = f"""
{topic}ì— ëŒ€í•œ ë²•ì  ê²€í† 

{topic} ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ì£¼ìš” ë¬¸ì œì ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

ë²•ì  ê·¼ê±°ì™€ ì ˆì°¨ë¥¼ ëª…í™•íˆ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

ì‹¤ë¬´ì—ì„œ ì£¼ì˜í•´ì•¼ í•  ì‚¬í•­ë“¤ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

ì „ë¬¸ê°€ ìƒë‹´ì„ í†µí•´ ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""
        
        return draft.strip()
    
    def _generate_rewrite(self, draft: str, topic: str, style_snippets: str, fact_snippets: str) -> str:
        """2ë‹¨ê³„: ìŠ¤íƒ€ì¼ ì ìš© ë° ë¦¬ë¼ì´íŒ… (1600-1900ì)"""
        # ê°€ì´ë“œ í”„ë¡¬í”„íŠ¸ ì½”ì–´ ì ìš©
        prompt = f"""
[ì—­í• ] ë²•ë¬´ë²•ì¸ ë¸”ë¡œê·¸ ì—ë””í„°(í•œêµ­ì–´). ì±„ê¶Œì ê´€ì .

[ìŠ¤íƒ€ì¼]
- ë„¤ì´ë²„ ë¸”ë¡œê·¸ í†¤(ì •ì¤‘Â·ì¹œì ˆ). ë¬¸ì¥/ë¬¸ë‹¨ ì§§ê²Œ(ë¬¸ë‹¨ 2â€“4ë¬¸ì¥).
- ì†Œì œëª©/ë²ˆí˜¸/ë¶ˆë¦¿ ì ê·¹ ì‚¬ìš©, ì´ëª¨ì§€ 0~1ê°œ/ì„¹ì…˜.
- ê¸ˆì§€: 'ë˜í•œ', 'ë”ë¶ˆì–´', ê³¼ì¥/í˜‘ë°•/ë¶ˆë²•ì¶”ì‹¬ ì¡°ì¥.

[ì‚¬ì‹¤ ì‚¬ìš© ê·œì¹™(ì¤‘ìš”)]
- ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ì˜ ì‚¬ì‹¤(ì •ì˜/ì ˆì°¨/ì„œë¥˜/ê¸°ê°„/ì£¼ì˜)ë§Œ ê·¼ê±°ë¡œ í•˜ë˜,
  ë¬¸ì¥Â·í‘œí˜„ì€ ì „ë¶€ ìƒˆë¡œ ì‘ì„±í•˜ì„¸ìš”. ì›ë¬¸ê³¼ 8-gram ë™ì¼ êµ¬ì ˆ ê¸ˆì§€.
- ì‚¬ë¡€ì˜ ê¸ˆì•¡/ë‚ ì§œ/ì§€ì—­/ë¶„í• íšŸìˆ˜ëŠ” í˜„ì‹¤ ë²”ìœ„ì—ì„œ "ìƒˆë¡œ" êµ¬ì„±.

[êµ¬ì¡°/ê¸¸ì´]
- ë„ì… â†’ ë¬¸ì œ ì¸ì‹ â†’ ë²•ì  ê·¼ê±°/ì ˆì°¨ â†’ ì‹¤ë¬´ ì¡°ì–¸(ì²´í¬ë¦¬ìŠ¤íŠ¸) â†’ ê²°ë¡ /CTA.
- ë³¸ë¬¸ 1,600â€“1,900ì, Markdown. ê° ì„¹ì…˜ ì†Œì œëª© í•„ìˆ˜.

[STYLE_SNIPPETS]  # í†¤ íŒíŠ¸ 1â€“3ë¬¸ì¥ (ë‚´ìš© ë³µë¶™ ê¸ˆì§€)
{style_snippets}

[FACT_SNIPPETS]   # ì ˆì°¨Â·ì„œë¥˜Â·ê¸°ê°„Â·ì£¼ì˜ ìš”ì§€(ì¬ì„œìˆ )
{fact_snippets}

[ì¶œë ¥] ìµœì¢… ë³¸ë¬¸ë§Œ ì¶œë ¥.
"""
        
        # ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„± (ì‹¤ì œë¡œëŠ” LLM í˜¸ì¶œ)
        rewrite = f"""# {topic}ì— ëŒ€í•œ ì¢…í•© ê°€ì´ë“œ

## ë„ì…

{topic}ê³¼ ê´€ë ¨ëœ ë²•ì  ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê²€í† í•´ë³´ê² ìŠµë‹ˆë‹¤. ë§ì€ ë¶„ë“¤ì´ ì´ ê³¼ì •ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆì–´, ëª…í™•í•œ ê°€ì´ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.

## ë¬¸ì œ ì¸ì‹

{topic} ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ì£¼ìš” ë¬¸ì œì ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- ë²•ì  ì ˆì°¨ì˜ ë³µì¡ì„±
- í•„ìš”í•œ ì„œë¥˜ì˜ ë‹¤ì–‘ì„±  
- ì‹œê°„ê³¼ ë¹„ìš©ì˜ ë¶€ë‹´
- ì „ë¬¸ ì§€ì‹ì˜ ë¶€ì¡±

## ë²•ì  ê·¼ê±°

{topic}ì€ ê´€ë ¨ ë²•ë ¹ì— ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ì§„í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì ì ˆí•œ ë²•ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì ‘ê·¼ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

## ì‹¤ë¬´ ì ˆì°¨

### 1ë‹¨ê³„: ì‚¬ì „ ì¤€ë¹„
- ê´€ë ¨ ì„œë¥˜ ìˆ˜ì§‘
- ë²•ì  ê²€í† 
- ì „ëµ ìˆ˜ë¦½

### 2ë‹¨ê³„: ë²•ì  ì¡°ì¹˜
- ì ì ˆí•œ ì ˆì°¨ ì§„í–‰
- ë²•ì  ìš”êµ¬ì‚¬í•­ ì¶©ì¡±
- ë¬¸ì„œí™”

### 3ë‹¨ê³„: í›„ì† ê´€ë¦¬
- ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
- í•„ìš”ì‹œ ì¶”ê°€ ì¡°ì¹˜
- ê²°ê³¼ ì •ë¦¬

## ì£¼ì˜ì‚¬í•­

{topic} ê³¼ì •ì—ì„œ ì£¼ì˜í•´ì•¼ í•  ì£¼ìš” ì‚¬í•­ë“¤:

- ë²•ì  ì ˆì°¨ì˜ ì—„ê²©í•œ ì¤€ìˆ˜
- ì‹œê°„ ì œí•œì˜ ê³ ë ¤
- ë¹„ìš© íš¨ìœ¨ì„±
- ì „ë¬¸ê°€ ìƒë‹´ì˜ ì¤‘ìš”ì„±

## ê²°ë¡ 

{topic}ì€ ì‹ ì¤‘í•˜ê³  ì²´ê³„ì ì¸ ì ‘ê·¼ì´ í•„ìš”í•œ ë²•ì  ì ˆì°¨ì…ë‹ˆë‹¤. ì „ë¬¸ê°€ì™€ì˜ ìƒë‹´ì„ í†µí•´ ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

**ìƒë‹´ ë¬¸ì˜: 02-1234-5678**

---

*ë³¸ ë‚´ìš©ì€ ì¼ë°˜ì ì¸ ê°€ì´ë“œì´ë©°, êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.*
"""
        
        return rewrite.strip()
    
    def _validate_content(self, content: str, sources: List[Dict]) -> Dict[str, Any]:
        """ì½˜í…ì¸  í’ˆì§ˆ ê²€ì¦"""
        results = {
            "ok": True,
            "errors": [],
            "warnings": [],
            "style_score": 0.0
        }
        
        # 1) ê¸¸ì´ ê²€ì¦
        if len(content) < self.config["rewrite_min_length"] or len(content) > self.config["rewrite_max_length"]:
            results["errors"].append(f"ê¸¸ì´ ë¶€ì ì ˆ: {len(content)}ì (ëª©í‘œ: {self.config['rewrite_min_length']}-{self.config['rewrite_max_length']}ì)")
            results["ok"] = False
        
        # 2) ì†Œì œëª© ê°œìˆ˜ í™•ì¸
        subheading_count = len(re.findall(r'^##\s+', content, re.MULTILINE))
        if subheading_count < self.config["min_subheadings"]:
            results["errors"].append(f"ì†Œì œëª© ë¶€ì¡±: {subheading_count}ê°œ (ìµœì†Œ {self.config['min_subheadings']}ê°œ í•„ìš”)")
            results["ok"] = False
        
        # 3) ì²´í¬ë¦¬ìŠ¤íŠ¸ ê°œìˆ˜ í™•ì¸
        checklist_count = len(re.findall(r'^\s*[-*]\s+', content, re.MULTILINE))
        if checklist_count < self.config["min_checklists"]:
            results["errors"].append(f"ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¶€ì¡±: {checklist_count}ê°œ (ìµœì†Œ {self.config['min_checklists']}ê°œ í•„ìš”)")
            results["ok"] = False
        
        # 4) ë¬¸ë‹¨ë³„ ë¬¸ì¥ ìˆ˜ í™•ì¸
        paragraphs = content.split('\n\n')
        for i, paragraph in enumerate(paragraphs):
            if paragraph.strip() and not paragraph.startswith('#'):
                sentences = len(re.findall(r'[.!?]', paragraph))
                if sentences > self.config["max_sentences_per_paragraph"]:
                    results["errors"].append(f"ë¬¸ë‹¨ {i+1}ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤: {sentences}ë¬¸ì¥ (ìµœëŒ€ {self.config['max_sentences_per_paragraph']}ë¬¸ì¥)")
                    results["ok"] = False
        
        # 5) ê¸ˆì¹™ì–´ ê²€ì¦
        for word in self.config["forbidden_words"]:
            if word in content:
                results["errors"].append(f"ê¸ˆì¹™ì–´ ë°œê²¬: '{word}'")
                results["ok"] = False
        
        # 6) ìŠ¤íƒ€ì¼ ì ìˆ˜ ê³„ì‚°
        style_score = self._calculate_style_score(content)
        results["style_score"] = style_score
        
        return results
    
    def _check_plagiarism(self, content: str, sources: List[Dict]) -> Dict[str, Any]:
        """í‘œì ˆ ê²€ì¦ (8-gram ì¤‘ë³µ ê²€ì‚¬)"""
        result = {
            "ok": True,
            "ngram8_overlap": 0.0,
            "cosine_max": 0.0,
            "simhash_dist": 0,
            "warnings": []
        }
        
        # 8-gram ì¤‘ë³µ ê²€ì‚¬
        content_ngrams = self._get_ngrams(content, 8)
        max_overlap = 0.0
        
        for source in sources:
            source_content = source.get("content", "")
            source_ngrams = self._get_ngrams(source_content, 8)
            
            if source_ngrams:
                overlap = len(content_ngrams & source_ngrams) / len(content_ngrams)
                max_overlap = max(max_overlap, overlap)
        
        result["ngram8_overlap"] = max_overlap
        
        if max_overlap > self.config["ngram8_threshold"]:
            result["ok"] = False
            result["warnings"].append(f"8-gram ì¤‘ë³µìœ¨ ì´ˆê³¼: {max_overlap:.3f} (ì„ê³„ê°’: {self.config['ngram8_threshold']})")
        
        return result
    
    def _get_ngrams(self, text: str, n: int) -> set:
        """n-gram ì¶”ì¶œ"""
        words = re.findall(r'\w+', text.lower())
        return set(' '.join(words[i:i+n]) for i in range(len(words)-n+1))
    
    def _calculate_style_score(self, content: str) -> float:
        """ìŠ¤íƒ€ì¼ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ë¬¸ë‹¨ ê¸¸ì´ ì ìˆ˜
        paragraphs = content.split('\n\n')
        avg_paragraph_length = sum(len(p.split('.')) for p in paragraphs if p.strip()) / len(paragraphs)
        if 2 <= avg_paragraph_length <= 4:
            score += 0.3
        
        # ì†Œì œëª© ì ìˆ˜
        subheading_count = len(re.findall(r'^##\s+', content, re.MULTILINE))
        if subheading_count >= 3:
            score += 0.3
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì ìˆ˜
        checklist_count = len(re.findall(r'^\s*[-*]\s+', content, re.MULTILINE))
        if checklist_count >= 1:
            score += 0.2
        
        # ê¸ˆì¹™ì–´ ì ìˆ˜
        has_forbidden = any(word in content for word in self.config["forbidden_words"])
        if not has_forbidden:
            score += 0.2
        
        return score
    
    def _auto_fix(self, content: str, validation_result: Dict, plagiarism_result: Dict) -> str:
        """ìë™ ìˆ˜ì • ì‹œë„"""
        fixed = content
        
        # ê¸¸ì´ ë³´ì •
        if len(fixed) < self.config["rewrite_min_length"]:
            fixed += "\n\n## ì¶”ê°€ ì •ë³´\n\në” ìì„¸í•œ ìƒë‹´ì´ í•„ìš”í•˜ì‹œë©´ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        # ì†Œì œëª© ë³´ì •
        if fixed.count("##") < self.config["min_subheadings"]:
            fixed = fixed.replace("## ê²°ë¡ ", "## ì‹¤ë¬´ ì¡°ì–¸\n\nì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œí•©ë‹ˆë‹¤.\n\n## ê²°ë¡ ")
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ë³´ì •
        if len(re.findall(r'^\s*[-*]\s+', fixed, re.MULTILINE)) < self.config["min_checklists"]:
            fixed = fixed.replace("## ê²°ë¡ ", "## ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n- ì „ë¬¸ê°€ ìƒë‹´\n- ë²•ì  ê²€í† \n- ì ˆì°¨ ì¤€ìˆ˜\n\n## ê²°ë¡ ")
        
        return fixed
    
    def _extract_title(self, content: str) -> str:
        """ì œëª© ì¶”ì¶œ"""
        lines = content.split('\n')
        for line in lines:
            if line.startswith('# '):
                return line[2:].strip()
        return "ë²•ì  ê²€í† "
    
    def _format_sources(self, results: List[Dict]) -> List[Dict]:
        """ì†ŒìŠ¤ í¬ë§·íŒ…"""
        return [
            {
                "title": r.get("title", ""),
                "url": r.get("url", ""),
                "score": r.get("similarity", 0.0)
            }
            for r in results[:5]  # ìƒìœ„ 5ê°œë§Œ
        ]
    
    def _fallback_content(self, topic: str) -> str:
        """í´ë°± ì½˜í…ì¸ """
        return f"""
# {topic}ì— ëŒ€í•œ ë²•ì  ê²€í† 

## ë„ì…
{topic}ê³¼ ê´€ë ¨ëœ ë²•ì  ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê²€í† í•´ë³´ê² ìŠµë‹ˆë‹¤.

## ë¬¸ì œ ì¸ì‹
ë§ì€ ë¶„ë“¤ì´ {topic} ê³¼ì •ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.

## ë²•ì  ê·¼ê±°
ê´€ë ¨ ë²•ë ¹ì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì ˆì°¨ë¥¼ ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

## ì‹¤ë¬´ ì ˆì°¨
1. ì‚¬ì „ ì¤€ë¹„
2. ë²•ì  ì¡°ì¹˜
3. í›„ì† ê´€ë¦¬

## ê²°ë¡ 
ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

**ìƒë‹´ ë¬¸ì˜: 02-1234-5678**
"""

def generate_guide_based_post(topic: str, search_results: List[Dict], 
                             category: str = "ì±„ê¶Œì¶”ì‹¬") -> Dict[str, Any]:
    """
    ê°€ì´ë“œ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì§„ì…ì 
    
    Args:
        topic: ì£¼ì œ
        search_results: ê²€ìƒ‰ ê²°ê³¼
        category: ì¹´í…Œê³ ë¦¬
        
    Returns:
        ìƒì„± ê²°ê³¼
    """
    generator = GuideBasedGenerator()
    return generator.generate_post(topic, search_results, category)





